{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d762ca93-c9bb-4d0a-8e0c-3d60c23cfcd6",
   "metadata": {},
   "source": [
    "## Feature Engineering "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "c6b2d1e8-7fcd-41df-8279-7ad7a6081d3e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from scipy import stats\n",
    "import modules.help_functions as hf\n",
    "import sklearn\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import cross_validate\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.preprocessing import PolynomialFeatures\n",
    "\n",
    "from sklearn.feature_selection import VarianceThreshold\n",
    "from sklearn.feature_selection import RFE\n",
    "\n",
    "import pickle\n",
    "\n",
    "from sklearn.pipeline import make_pipeline\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "dbb17ee8-0353-44f0-8975-d72d4dd314d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# read in file\n",
    "df = pd.read_csv('../data/encoded_training_data_v5.csv')\n",
    "# df_delays = hf.get_avg_dest_delay(df, ['carrier_delay', 'weather_delay', 'nas_delay', 'security_delay', 'late_aircraft_delay'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5fa9e30f",
   "metadata": {
    "tags": []
   },
   "source": [
    "### XGBOOST"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "ccf614a1-090d-4c3d-b19c-ea2772f759ea",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE(test): 255.1673464202419 R2(test): 0.13331237317933997 MAE(test): 12.401466715820652\n"
     ]
    }
   ],
   "source": [
    "# XGboost Model\n",
    "import xgboost as xgb\n",
    "from sklearn.metrics import mean_squared_error, r2_score, mean_absolute_error\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "y = df.arr_delay.to_numpy()\n",
    "X = df.drop(columns=['arr_delay']).to_numpy()\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.25, random_state=88)\n",
    "data_dmatrix = xgb.DMatrix(data=X_train, label=y_train)\n",
    "\n",
    "xgb = xgb.XGBRegressor(learning_rate = 0.51,\n",
    "                       max_depth = 7,                        \n",
    "                       alpha = 60,\n",
    "                       n_estimators = 84, \n",
    "                       n_jobs = -1, \n",
    "                       subsample = 0.85,\n",
    "                       colsample_bytree = 0.85,\n",
    "                       reg_lambda = 59.1,\n",
    "                       gamma = 0,\n",
    "                       min_child_weight = 1,\n",
    "                       max_delta_step = 0,\n",
    "                       sampling_method = 'uniform'        \n",
    "                      )\n",
    "\n",
    "\n",
    "xgb.fit(X_train, y_train)\n",
    "y_pred = xgb.predict(X_test)\n",
    "\n",
    "print(f'MSE(test): {mean_squared_error(y_test, y_pred)}',\n",
    "      f'R2(test): {r2_score(y_test, y_pred)}', \n",
    "      f'MAE(test): {mean_absolute_error(y_test, y_pred)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "6921bf3b-e006-4647-92c0-cfcf274f7e64",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# XGboost Cross Validation\n",
    "# import xgboost as xgb\n",
    "# from sklearn.metrics import mean_squared_error, r2_score\n",
    "# from sklearn.model_selection import train_test_split\n",
    "# from numpy import absolute\n",
    "# from sklearn.model_selection import cross_val_score\n",
    "# from sklearn.model_selection import RepeatedKFold\n",
    "# from sklearn.model_selection import KFold\n",
    "# from sklearn.model_selection import cross_validate\n",
    "\n",
    "# y = df.arr_delay.to_numpy()\n",
    "# X = df.drop(columns=['arr_delay']).to_numpy()\n",
    "# X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.25, random_state=88)\n",
    "# data_dmatrix = xgb.DMatrix(data=X_train,label=y_train)\n",
    "\n",
    "# xgb = xgb.XGBRegressor(\n",
    "#                         )\n",
    "\n",
    "# # do the split\n",
    "# cv = KFold(n_splits=5)\n",
    "\n",
    "# # perform validation\n",
    "# scoring = ['neg_mean_absolute_error', 'neg_mean_squared_error', 'r2', 'neg_root_mean_squared_error']\n",
    "# scores = cross_validate(xgb, X_train, y_train, scoring=scoring, cv=cv, n_jobs=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "da02e748-ac0a-4c36-8d3c-e18f7dc164f1",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Display the CV result\n",
    "# mse = absolute(scores['test_neg_mean_squared_error']).mean()\n",
    "# r2 = scores['test_r2'].mean()\n",
    "# mae = absolute(scores['test_neg_mean_absolute_error'].mean())\n",
    "# print(f'MSE(train_cv): {mse}',\n",
    "#       f'R2(train_cv): {r2}',\n",
    "#       f'MAE(train_cv): {mae}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "14007a82",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Grid Search for XBBoost\n",
    "# DON'T RUN\n",
    "# from sklearn.model_selection import GridSearchCV\n",
    "# from xgboost import XGBRegressor\n",
    "\n",
    "# y = df.arr_delay.to_numpy()\n",
    "# X = df.drop(columns=['arr_delay']).to_numpy()\n",
    "# X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2)\n",
    "# xgb = XGBRegressor()\n",
    "\n",
    "# params = {\n",
    "#     'learning_rate': np.arange(1, 1.1, 0.01),\n",
    "#     'max_depth': np.arange(6, 9, 1),\n",
    "#     'alpha': np.arange(50, 55, 1),\n",
    "#     'n_estimators': np.arange(25, 30, 1),\n",
    "#     'colsample_bytree': np.arange(0.7, 0.9, 0.05)\n",
    "# }\n",
    "\n",
    "# xgb_grid_search = GridSearchCV(xgb, \n",
    "#                                param_grid=params, \n",
    "#                                cv=5, \n",
    "#                                n_jobs=6, \n",
    "#                                error_score='raise', \n",
    "#                                verbose=True)\n",
    "# xgb_grid_search.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "487c745f",
   "metadata": {
    "tags": []
   },
   "source": [
    "### SVM "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "9f6b20ba",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# # Grid Search for estimator SVM\n",
    "# import xgboost as xgb\n",
    "# from sklearn.metrics import mean_squared_error, r2_score\n",
    "# from sklearn.model_selection import train_test_split\n",
    "# from sklearn.svm import SVR\n",
    "\n",
    "# y = df.arr_delay.to_numpy()\n",
    "# X = df.drop(columns=['arr_delay']).to_numpy()\n",
    "# X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.25)\n",
    "\n",
    "# svm = svm.SVR()\n",
    "\n",
    "# params = {\n",
    "#     'C': np.arange(1, 2.5, 0.1),\n",
    "#     'probability': [True, False],\n",
    "# }\n",
    "\n",
    "# svm_grid_search = GridSearchCV(svm, \n",
    "#                            param_grid=params, \n",
    "#                            cv=5, \n",
    "#                            n_jobs=-1, \n",
    "#                            error_score='raise', \n",
    "#                            verbose=True)\n",
    "# svm_grid_search.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "bef4738f",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LibSVM]MSE: 272.4362563578315 R2: 0.07465772640905877\n"
     ]
    }
   ],
   "source": [
    "# svm model\n",
    "from sklearn.svm import SVR\n",
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "\n",
    "#Create a svm Classifier\n",
    "svm_reg = SVR(verbose=True)\n",
    "\n",
    "#Train the model using the training sets\n",
    "svm_reg.fit(X_train, y_train)\n",
    "\n",
    "#Predict the response for test dataset\n",
    "y_pred = svm_reg.predict(X_test)\n",
    "print(f'MSE: {mean_squared_error(y_test, y_pred)}', f'R2: {r2_score(y_test, y_pred)}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ec30a655-9d44-4a78-904a-e938abb8c078",
   "metadata": {
    "tags": []
   },
   "source": [
    "## AdaBoost Regressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "6178dc33-3aa4-41ca-9b28-a16bfbc8ccee",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE(test): 299.1954934737365 R2(test): -0.016231253066080198 MAE(test): 14.059891568429437\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import AdaBoostRegressor \n",
    "from sklearn.metrics import mean_squared_error, r2_score, mean_absolute_error\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "y = df.arr_delay.to_numpy()\n",
    "X = df.drop(columns=['arr_delay']).to_numpy()\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.25, random_state=88)\n",
    "\n",
    "ada = AdaBoostRegressor()\n",
    "\n",
    "ada.fit(X_train, y_train)\n",
    "y_pred = ada.predict(X_test)\n",
    "\n",
    "print(f'MSE(test): {mean_squared_error(y_test, y_pred)}',\n",
    "      f'R2(test): {r2_score(y_test, y_pred)}', \n",
    "      f'MAE(test): {mean_absolute_error(y_test, y_pred)}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e8d8ac6f-8f65-4051-80c5-e6c70b02ef4e",
   "metadata": {},
   "source": [
    "## SVM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "5a5fb50c-278d-4d7f-a560-c488038ded08",
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'skearn'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-26-ee38b8d59279>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[1;32mfrom\u001b[0m \u001b[0mskearn\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msvm\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mSVR\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      2\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0msklearn\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmetrics\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mmean_squared_error\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mr2_score\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmean_absolute_error\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0msklearn\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmodel_selection\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mtrain_test_split\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[0my\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mdf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0marr_delay\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mto_numpy\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'skearn'"
     ]
    }
   ],
   "source": [
    "from sklearn.svm import SVR\n",
    "from sklearn.metrics import mean_squared_error, r2_score, mean_absolute_error\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "y = df.arr_delay.to_numpy()\n",
    "X = df.drop(columns=['arr_delay']).to_numpy()\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.25, random_state=88)\n",
    "\n",
    "svr = SVR()\n",
    "\n",
    "svr.fit(X_train, y_train)\n",
    "y_pred = svr.predict(X_test)\n",
    "\n",
    "print(f'MSE(test): {mean_squared_error(y_test, y_pred)}',\n",
    "      f'R2(test): {r2_score(y_test, y_pred)}', \n",
    "      f'MAE(test): {mean_absolute_error(y_test, y_pred)}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "693d9faf-b4e5-4315-9641-8239289e2fab",
   "metadata": {},
   "source": [
    "# Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "84edabf9-bcd0-4cd2-8875-64f634adf963",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE(test): 317.7557421592085 R2(test): -0.07927199127997642 MAE(test): 13.726514526508495\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.metrics import mean_squared_error, r2_score, mean_absolute_error\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "y = df.arr_delay.to_numpy()\n",
    "X = df.drop(columns=['arr_delay']).to_numpy()\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.25, random_state=88)\n",
    "\n",
    "rfr = RandomForestRegressor()\n",
    "\n",
    "rfr.fit(X_train, y_train)\n",
    "y_pred = rfr.predict(X_test)\n",
    "\n",
    "print(f'MSE(test): {mean_squared_error(y_test, y_pred)}',\n",
    "      f'R2(test): {r2_score(y_test, y_pred)}', \n",
    "      f'MAE(test): {mean_absolute_error(y_test, y_pred)}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f2e022b7-9dcc-485d-92f0-0db8177885ef",
   "metadata": {},
   "source": [
    "## Bagging Regressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "c3741fe8-5947-4ecb-a052-be5ca793ab58",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE(test): 335.0010462906602 R2(test): -0.1378464598441198 MAE(test): 14.09878593390384\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import BaggingRegressor\n",
    "from sklearn.metrics import mean_squared_error, r2_score, mean_absolute_error\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "y = df.arr_delay.to_numpy()\n",
    "X = df.drop(columns=['arr_delay']).to_numpy()\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.25, random_state=88)\n",
    "\n",
    "bag = BaggingRegressor()\n",
    "\n",
    "bag.fit(X_train, y_train)\n",
    "y_pred = bag.predict(X_test)\n",
    "\n",
    "print(f'MSE(test): {mean_squared_error(y_test, y_pred)}',\n",
    "      f'R2(test): {r2_score(y_test, y_pred)}', \n",
    "      f'MAE(test): {mean_absolute_error(y_test, y_pred)}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "211ae256-1634-4f52-9ca0-b8a602cc9abe",
   "metadata": {},
   "source": [
    "## GradientBoosting Regressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "ae382ccf-5868-4e3b-8f53-84f607a9775c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE(test): 272.3731765263293 R2(test): 0.07487197995768824 MAE(test): 12.850633238016195\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import GradientBoostingRegressor\n",
    "from sklearn.metrics import mean_squared_error, r2_score, mean_absolute_error\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "y = df.arr_delay.to_numpy()\n",
    "X = df.drop(columns=['arr_delay']).to_numpy()\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.25, random_state=88)\n",
    "\n",
    "gb_reg = GradientBoostingRegressor()\n",
    "\n",
    "gb_reg.fit(X_train, y_train)\n",
    "y_pred = gb_reg.predict(X_test)\n",
    "\n",
    "print(f'MSE(test): {mean_squared_error(y_test, y_pred)}',\n",
    "      f'R2(test): {r2_score(y_test, y_pred)}', \n",
    "      f'MAE(test): {mean_absolute_error(y_test, y_pred)}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1d52648e-49dd-437e-b024-9ff8f9412fed",
   "metadata": {},
   "source": [
    "## Voting Regressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "b7509603-3e1d-4885-89fa-734f30d9dbd4",
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "__init__() missing 1 required positional argument: 'estimators'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-30-c5c6aeab0685>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      7\u001b[0m \u001b[0mX_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mX_test\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_test\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtrain_test_split\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtest_size\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m0.25\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mrandom_state\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m88\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      8\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 9\u001b[1;33m \u001b[0mv_reg\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mVotingRegressor\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     10\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     11\u001b[0m \u001b[0mv_reg\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mTypeError\u001b[0m: __init__() missing 1 required positional argument: 'estimators'"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import VotingRegressor\n",
    "from sklearn.metrics import mean_squared_error, r2_score, mean_absolute_error\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "y = df.arr_delay.to_numpy()\n",
    "X = df.drop(columns=['arr_delay']).to_numpy()\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.25, random_state=88)\n",
    "\n",
    "v_reg = VotingRegressor(estimators=)\n",
    "\n",
    "v_reg.fit(X_train, y_train)\n",
    "y_pred = v_reg.predict(X_test)\n",
    "\n",
    "print(f'MSE(test): {mean_squared_error(y_test, y_pred)}',\n",
    "      f'R2(test): {r2_score(y_test, y_pred)}', \n",
    "      f'MAE(test): {mean_absolute_error(y_test, y_pred)}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "25a2a8cb-1812-4476-bb84-cd8490cfbbeb",
   "metadata": {},
   "source": [
    "## HistGradientBoosting Regressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "9b3fcdd5-5aae-4a12-b25d-7430b5b06ad2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE(test): 263.30785151482485 R2(test): 0.10566277325785911 MAE(test): 12.628034138924694\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import HistGradientBoostingRegressor\n",
    "from sklearn.metrics import mean_squared_error, r2_score, mean_absolute_error\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "y = df.arr_delay.to_numpy()\n",
    "X = df.drop(columns=['arr_delay']).to_numpy()\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.25, random_state=88)\n",
    "\n",
    "hgb_reg = HistGradientBoostingRegressor(learning_rate=0.1,\n",
    "                                        max_iter=100,\n",
    "                                        max_leaf_nodes=31,\n",
    "                                        max_depth=20,\n",
    "                                        min_samples_leaf=20,\n",
    "                                        l2_regularization=0.1)\n",
    "\n",
    "hgb_reg.fit(X_train, y_train)\n",
    "y_pred = hgb_reg.predict(X_test)\n",
    "\n",
    "print(f'MSE(test): {mean_squared_error(y_test, y_pred)}',\n",
    "      f'R2(test): {r2_score(y_test, y_pred)}', \n",
    "      f'MAE(test): {mean_absolute_error(y_test, y_pred)}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dfc60175-259a-4fb4-bd35-aef5208ff990",
   "metadata": {},
   "source": [
    "## Stacking Regressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "44c3492c-8ec0-4d9e-8b1c-2d0ed5d15251",
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "'numpy.int32' object is not iterable",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-38-074cc3988a7e>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      9\u001b[0m \u001b[0mst_reg\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mStackingRegressor\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mestimators\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0marange\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m20\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     10\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 11\u001b[1;33m \u001b[0mst_reg\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     12\u001b[0m \u001b[0my_pred\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mst_reg\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_test\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     13\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\bootcamp\\lib\\site-packages\\sklearn\\ensemble\\_stacking.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, X, y, sample_weight)\u001b[0m\n\u001b[0;32m    751\u001b[0m         \"\"\"\n\u001b[0;32m    752\u001b[0m         \u001b[0my\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcolumn_or_1d\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mwarn\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 753\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0msuper\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msample_weight\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    754\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    755\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mtransform\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mX\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\bootcamp\\lib\\site-packages\\sklearn\\ensemble\\_stacking.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, X, y, sample_weight)\u001b[0m\n\u001b[0;32m    148\u001b[0m         \u001b[1;31m# all_estimators contains all estimators, the one to be fitted and the\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    149\u001b[0m         \u001b[1;31m# 'drop' string.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 150\u001b[1;33m         \u001b[0mnames\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mall_estimators\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_validate_estimators\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    151\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_validate_final_estimator\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    152\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\bootcamp\\lib\\site-packages\\sklearn\\ensemble\\_base.py\u001b[0m in \u001b[0;36m_validate_estimators\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    245\u001b[0m                 \u001b[1;34m\" of (string, estimator) tuples.\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    246\u001b[0m             )\n\u001b[1;32m--> 247\u001b[1;33m         \u001b[0mnames\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mestimators\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mzip\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mestimators\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    248\u001b[0m         \u001b[1;31m# defined by MetaEstimatorMixin\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    249\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_validate_names\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnames\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mTypeError\u001b[0m: 'numpy.int32' object is not iterable"
     ]
    }
   ],
   "source": [
    "# DONT' RUN\n",
    "from sklearn.ensemble import StackingRegressor\n",
    "from sklearn.metrics import mean_squared_error, r2_score, mean_absolute_error\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "y = df.arr_delay.to_numpy()\n",
    "X = df.drop(columns=['arr_delay']).to_numpy()\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.25, random_state=88)\n",
    "\n",
    "st_reg = StackingRegressor(estimators=)\n",
    "\n",
    "st_reg.fit(X_train, y_train)\n",
    "y_pred = st_reg.predict(X_test)\n",
    "\n",
    "print(f'MSE(test): {mean_squared_error(y_test, y_pred)}',\n",
    "      f'R2(test): {r2_score(y_test, y_pred)}', \n",
    "      f'MAE(test): {mean_absolute_error(y_test, y_pred)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f1692f8",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "bootcamp",
   "language": "python",
   "name": "bootcamp"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
