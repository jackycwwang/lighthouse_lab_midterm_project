{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d544f8a1-ee71-40d9-bdc7-724dbb7d5ebb",
   "metadata": {},
   "source": [
    "## Data Wrangling and Data Exploration Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "69a792dd-00a5-444b-9d8f-55ad38c1369d",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Data_wrangling:\n",
    "    \n",
    "    def __init__(self, df):\n",
    "        self.df = df\n",
    "        \n",
    "    def drop_columns(self, column_names_as_list):\n",
    "        \"\"\" removes columns if exist in dataframe\n",
    "        Note ones that probably should be removed are [\"dup\", \"index\", \"no_name\", \"cancellation_code\" ]\"\"\"\n",
    "        for i in range(len(column_names_as_list)):\n",
    "            if column_names_as_list[i] in df:\n",
    "                self.df = self.df.drop(column_names_as_list[i], axis = 1)\n",
    "        return self.df\n",
    "\n",
    "    def create_haul_type(self):\n",
    "        \"\"\" adds short:0, mid:1, long:2 range haul types from crs_elapsed_time (scheduled) \"\"\"\n",
    "\n",
    "        self.df[\"haul_type\"] = self.df['crs_elapsed_time']\n",
    "        self.df[\"haul_type\"].mask(self.df[\"haul_type\"].values < 180, 0, inplace=True)\n",
    "        self.df[\"haul_type\"].mask((self.df[\"haul_type\"] >= 180) & (self.df[\"haul_type\"] < 360), 1, inplace=True)\n",
    "        self.df[\"haul_type\"].mask((self.df[\"haul_type\"] >= 360), 2, inplace=True) \n",
    "        df[\"haul_type\"]= df[\"haul_type\"].astype('int')\n",
    "        return self.df\n",
    "    \n",
    "\n",
    "    \n",
    "def split_time_of_day_departure(df):\n",
    "    \"\"\" takes estimated time of departure and splits in to hours 24 hour clock (local time) \"\"\"\n",
    "    df['dep_hour'] = df['crs_dep_time']\n",
    "    df['dep_hour'] = np.floor(df['dep_hour']/100).astype(\"int\")\n",
    "    return df\n",
    "  \n",
    "    \n",
    "def split_time_of_day_arrival(df):\n",
    "    \"\"\" takes estimated time of arrival and splits in to hours 24 hour clock (local time) \"\"\"\n",
    "    df['arr_hour'] = df['crs_arr_time']\n",
    "    df['arr_hour'] = np.floor(df['arr_hour']/100).astype(\"int\")\n",
    "    return df\n",
    "    \n",
    "    \n",
    "def split_dest_city_state(df):\n",
    "    \"\"\" separates destination city and states into own columns\"\"\"\n",
    "    df['dest_state'] = df['dest_city_name']\n",
    "    df['dest_city'] = df['dest_city_name']\n",
    "    \n",
    "    f_state= lambda x: x.split(sep=', ')[1]\n",
    "    f_city= lambda x: x.split(sep=', ')[0]\n",
    "\n",
    "    df['dest_state'] = df['dest_state'].apply(f_state)\n",
    "    df['dest_city'] = df['dest_city'].apply(f_city)\n",
    "    return df\n",
    "\n",
    "\n",
    "def split_origin_city_state(df):\n",
    "    \"\"\" separates origin city and states into own columns\"\"\"\n",
    "    df['origin_state'] = df['origin_city_name']\n",
    "    df['origin_city'] = df['origin_city_name']\n",
    "    \n",
    "    f_state= lambda x: x.split(sep=', ')[1]\n",
    "    f_city= lambda x: x.split(sep=', ')[0]\n",
    "\n",
    "    df['origin_state'] = df['origin_state'].apply(f_state)\n",
    "    df['origin_city'] = df['origin_city'].apply(f_city)\n",
    "    return df\n",
    "\n",
    "\n",
    "def add_is_weekend_feature(df):\n",
    "    \"\"\" creates boolean column to indicate if week is weekend \n",
    "        https://pandas.pydata.org/docs/reference/api/pandas.DatetimeIndex.weekday.html\n",
    "        week starts 0 with monday - 0-5 are weekdays (0) and 6,7 weekends (1) \"\"\"\n",
    "\n",
    "    df['weekend'] = df['fl_date'].astype('datetime64[ns]')\n",
    "\n",
    "    f = lambda x: x.weekday()     \n",
    "    df['weekend'] = df['weekend'].apply(f).astype('int32')\n",
    "    df['weekend'].replace({\n",
    "            0:0,\n",
    "            1:0,\n",
    "            2:0,\n",
    "            3:0,\n",
    "            4:0,\n",
    "            5:0,\n",
    "            6:1,\n",
    "            7:1\n",
    "        }, inplace=True)\n",
    "    return df\n",
    "\n",
    "def add_weekday(df):\n",
    "    \"\"\" creates boolean column to indicate day of week \n",
    "        https://pandas.pydata.org/docs/reference/api/pandas.DatetimeIndex.weekday.html\n",
    "        week starts 0 with monday) \"\"\"\n",
    "\n",
    "    df['weekday'] = df['fl_date'].astype('datetime64[ns]')\n",
    "\n",
    "    f = lambda x: x.weekday()     \n",
    "    df['weekday'] = df['weekday'].apply(f).astype('int32')\n",
    "    return df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "57ad28a3-a547-4995-9c13-2d7914bf48f7",
   "metadata": {},
   "source": [
    "## Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a984f61-75f5-45d0-9a82-360842c50574",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Preprocessing:\n",
    "    def __init__(self, df):\n",
    "        self.df = df\n",
    "        \n",
    "    def split_numeric_categorical(self):\n",
    "        pass\n",
    "        \n",
    "    def scale(self, scalar):\n",
    "        pass\n",
    "    \n",
    "    def remove_highly_correlated_columns(self):\n",
    "        pass\n",
    "    \n",
    "    def drop_targets(self):\n",
    "        \"\"\" removes target variables before modelling\"\"\"\n",
    "#         return drop_columns(self.df, ['carrier_delay', 'weather_delay', 'nas_delay', 'security_delay'])\n",
    "        pass\n",
    "   \n",
    "\n",
    "def remove_highly_correlated_features(df, correlation_threshold=0.8):\n",
    "    #     Anything above correlation threshold will be tossed\n",
    "    # Assumptions - all numeric, target variable removed\n",
    "    # step 1\n",
    "    df_corr = df.corr().abs()\n",
    "\n",
    "    # step 2\n",
    "    indices = np.where(df_corr > correlation_threshold)\n",
    "    indices = [(df_corr.index[x], df_corr.columns[y])\n",
    "    for x, y in zip(*indices)\n",
    "        if x != y and x < y]\n",
    "\n",
    "    # step 3\n",
    "    for idx in indices: #each pair\n",
    "        try:\n",
    "            df.drop(idx[1], axis = 1, inplace=True)\n",
    "        except KeyError:\n",
    "            pass\n",
    "    return(df)\n",
    "\n",
    " \n",
    "def remove_small_variance(x, variance_threshold = 0.1):\n",
    "    # Assumptions - target variable removed, df is numeric\n",
    "    # import:\n",
    "    # from sklearn.feature_selection import VarianceThreshold\n",
    "    vt = VarianceThreshold(variance_threshold)\n",
    "    x_transformed = vt.fit_transform(x)\n",
    "    selected_columns = x.columns[vt.get_support()]\n",
    "    x_transformed = pd.DataFrame(x_transformed, columns = selected_columns)\n",
    "    return(x_transformed)\n",
    "\n",
    "def remove_missing_values(x, missing_percent_drop_threshold=0.5):\n",
    "#     takes in dataframe, removes missing above a percent threshold - percent out of 1\n",
    "    total = x.isnull().sum().sort_values(ascending=False)\n",
    "    percent = (x.isnull().sum()/x.isnull().count()).sort_values(ascending=False)\n",
    "    missing_data = pd.concat([total, percent], axis=1, keys=['Total', 'Percent'])\n",
    "    missing_data.head(20)\n",
    "\n",
    "    to_drop = missing_data[missing_data['Percent'] > missing_percent_drop_threshold].index.tolist()\n",
    "    return(x.drop(to_drop, axis=1, inplace=True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "098a0707-3607-4725-a128-085fd621d0fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ONE HOT ENCODING\n",
    "\n",
    "def encode_and_bind(original_dataframe, feature_to_encode):\n",
    "    dummies = pd.get_dummies(original_dataframe[[feature_to_encode]])\n",
    "    res = pd.concat([original_dataframe, dummies], axis=1)\n",
    "#     res = res.drop([feature_to_encode], axis=1)\n",
    "    return(res)\n",
    "\n",
    "cat_feats = ['Item_Fat_Content', 'Item_Type', 'Outlet_Size', 'Outlet_Location_Type', 'Outlet_Type', 'Broad_Item_Type']\n",
    "# cat_feats = data[].index.tolist()\n",
    "df_dummy = pd.get_dummies(data[cat_feats])\n",
    "df_dummy.head()\n",
    "\n",
    "# encode_and_bind(imdb_movies, 'Rated')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9e4257ee-df9e-4cd8-9955-d6baac40dbe2",
   "metadata": {},
   "source": [
    "# Formating Test Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "5c6acfbd-4110-4d9a-b821-7239dc60d8da",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "df = pd.read_csv('../data/flights_samp.csv')\n",
    "\n",
    "# import fresh df from .csv before using this  otherwise will get double 00:00:00\n",
    "def convert_testtrain_data_to_test_format(df):\n",
    "    \"\"\" Convert our testing data to be in the same format as the data to test (drop columns and reformat date)\"\"\"\n",
    "    \n",
    "    #convert date to datetime with 0's\n",
    "    df.fl_date = (df.fl_date + ' 00:00:00')\n",
    "    pd.to_datetime(df['fl_date'])\n",
    "    \n",
    "    #drop columns not present in test format\n",
    "    df.drop(columns=['index', 'dep_time',\n",
    "       'dep_delay', 'taxi_out', 'wheels_off', 'wheels_on', 'taxi_in', 'arr_time', 'arr_delay', 'cancelled',\n",
    "       'cancellation_code', 'diverted', 'actual_elapsed_time', 'air_time', \n",
    "       'carrier_delay', 'weather_delay', 'nas_delay', 'security_delay',\n",
    "       'late_aircraft_delay', 'first_dep_time', 'total_add_gtime',\n",
    "       'longest_add_gtime', 'no_name'], inplace = True)\n",
    "    return df\n",
    "df_new = convert_testtrain_data_to_test_format(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "46051c94-d76e-4466-a2bb-b7bec4126f8f",
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "replace() missing 1 required positional argument: 'repl'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-78-67cd7dc0ad96>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     53\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mdf\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     54\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 55\u001b[0;31m \u001b[0mdf_new\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mconvert_from_test_format_to_fit_predict_format\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdf_new\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-78-67cd7dc0ad96>\u001b[0m in \u001b[0;36mconvert_from_test_format_to_fit_predict_format\u001b[0;34m(df)\u001b[0m\n\u001b[1;32m     19\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     20\u001b[0m     \u001b[0;31m# Dest City - Encode\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 21\u001b[0;31m     df = df.dest_city.str.replace({'CA': 10,\n\u001b[0m\u001b[1;32m     22\u001b[0m                              \u001b[0;34m'TX'\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;36m9\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     23\u001b[0m                              \u001b[0;34m'FL'\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;36m8\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/envs/bootcamp_env/lib/python3.8/site-packages/pandas/core/strings/accessor.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    114\u001b[0m                 )\n\u001b[1;32m    115\u001b[0m                 \u001b[0;32mraise\u001b[0m \u001b[0mTypeError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmsg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 116\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    117\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    118\u001b[0m         \u001b[0mwrapper\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__name__\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfunc_name\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: replace() missing 1 required positional argument: 'repl'"
     ]
    }
   ],
   "source": [
    "def convert_from_test_format_to_fit_predict_format(df):\n",
    "    \"\"\"Adds in columns for model fitting and converts to numeric/ encoded categorical for ML model\"\"\"\n",
    "    \n",
    "    # Split crs_arr_time and crs_dep_time into hour of day (local)\n",
    "    df = split_time_of_day_departure(df)\n",
    "    df = split_time_of_day_arrival(df)\n",
    "    df.drop(columns=['crs_dep_time', 'crs_arr_time'], inplace=True)\n",
    "    \n",
    "    # Convert fl_date into day of week  # NOTE MAY WANT TO ADD BACK IN MONTH OR JAN 1 days\n",
    "    df = add_weekday(df)  \n",
    "    df.drop(columns=['fl_date'], inplace=True)\n",
    "    df.weekday = df.weekday.astype(str)\n",
    "    df = encode_and_bind(df, 'weekday')\n",
    "    \n",
    "    # Split city and state \n",
    "    split_origin_city_state(df)\n",
    "    split_dest_city_state(df)\n",
    "    df.drop(columns=['dest_city_name', 'origin_city_name'], inplace=True)\n",
    "\n",
    "    # Dest City - Encode\n",
    "    df = df.dest_city.str.replace({'CA': 10,\n",
    "                             'TX': 9,\n",
    "                             'FL': 8,\n",
    "                             'IL': 7,\n",
    "                             'NY': 6,\n",
    "                             'GA': 5,\n",
    "                             'NC': 4,\n",
    "                             'CO': 3,\n",
    "                             'PA': 2,\n",
    "                             'WA': 1}, regex=False)\n",
    "\n",
    "    # Dest State - Encode\n",
    "    \n",
    "    # Origin City - Encode\n",
    "    \n",
    "    # Origin State - Encode\n",
    "\n",
    "    # Convert Carrier - Encode \n",
    "    df = encode_and_bind(df, 'mkt_unique_carrier')\n",
    "\n",
    "    # Origin Airport - Encode top 10 (rest in 'other') or bin according to passenger or flight volume\n",
    "    \n",
    "    # Dest Airport - Encode top 10 or bin according to passenger of flight volume \n",
    "    \n",
    "    # Flight number ??? # drop for now?\n",
    "    df.drop(columns = ['mkt_carrier_fl_num'], inplace=True)\n",
    "    \n",
    "    # Drop rest\n",
    "    df.drop(columns=['branded_code_share', 'mkt_carrier','op_unique_carrier', 'tail_num', \n",
    "                     'op_carrier_fl_num', 'origin_airport_id', 'dest_airport_id', 'dup', 'flights'], inplace = True)\n",
    "    \n",
    "    \n",
    "    return df\n",
    "\n",
    "df_new = convert_from_test_format_to_fit_predict_format(df_new)    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "c923f7bd-7440-4e96-b1a4-72de61188078",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['origin', 'dest', 'crs_elapsed_time', 'distance', 'dep_hour',\n",
       "       'arr_hour', 'weekday_0', 'weekday_1', 'weekday_2', 'weekday_3',\n",
       "       'weekday_4', 'weekday_5', 'weekday_6', 'origin_state', 'origin_city',\n",
       "       'dest_state', 'dest_city', 'mkt_unique_carrier_AA',\n",
       "       'mkt_unique_carrier_AS', 'mkt_unique_carrier_B6',\n",
       "       'mkt_unique_carrier_DL', 'mkt_unique_carrier_F9',\n",
       "       'mkt_unique_carrier_G4', 'mkt_unique_carrier_HA',\n",
       "       'mkt_unique_carrier_NK', 'mkt_unique_carrier_UA',\n",
       "       'mkt_unique_carrier_WN'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_new.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "e67e0fab-4cb3-4438-b974-5aa128c4ecff",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>origin</th>\n",
       "      <th>dest</th>\n",
       "      <th>crs_elapsed_time</th>\n",
       "      <th>distance</th>\n",
       "      <th>dep_hour</th>\n",
       "      <th>arr_hour</th>\n",
       "      <th>weekday_0</th>\n",
       "      <th>weekday_1</th>\n",
       "      <th>weekday_2</th>\n",
       "      <th>weekday_3</th>\n",
       "      <th>...</th>\n",
       "      <th>mkt_unique_carrier_AA</th>\n",
       "      <th>mkt_unique_carrier_AS</th>\n",
       "      <th>mkt_unique_carrier_B6</th>\n",
       "      <th>mkt_unique_carrier_DL</th>\n",
       "      <th>mkt_unique_carrier_F9</th>\n",
       "      <th>mkt_unique_carrier_G4</th>\n",
       "      <th>mkt_unique_carrier_HA</th>\n",
       "      <th>mkt_unique_carrier_NK</th>\n",
       "      <th>mkt_unique_carrier_UA</th>\n",
       "      <th>mkt_unique_carrier_WN</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>LAX</td>\n",
       "      <td>ORD</td>\n",
       "      <td>251.0</td>\n",
       "      <td>1744.0</td>\n",
       "      <td>0</td>\n",
       "      <td>7</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ORD</td>\n",
       "      <td>AZO</td>\n",
       "      <td>58.0</td>\n",
       "      <td>122.0</td>\n",
       "      <td>21</td>\n",
       "      <td>23</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>OMA</td>\n",
       "      <td>PHX</td>\n",
       "      <td>175.0</td>\n",
       "      <td>1037.0</td>\n",
       "      <td>16</td>\n",
       "      <td>18</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>TPA</td>\n",
       "      <td>MSY</td>\n",
       "      <td>95.0</td>\n",
       "      <td>488.0</td>\n",
       "      <td>10</td>\n",
       "      <td>10</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>EWR</td>\n",
       "      <td>DCA</td>\n",
       "      <td>86.0</td>\n",
       "      <td>199.0</td>\n",
       "      <td>18</td>\n",
       "      <td>19</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 27 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "  origin dest  crs_elapsed_time  distance  dep_hour  arr_hour  weekday_0  \\\n",
       "0    LAX  ORD             251.0    1744.0         0         7          1   \n",
       "1    ORD  AZO              58.0     122.0        21        23          0   \n",
       "2    OMA  PHX             175.0    1037.0        16        18          0   \n",
       "3    TPA  MSY              95.0     488.0        10        10          0   \n",
       "4    EWR  DCA              86.0     199.0        18        19          0   \n",
       "\n",
       "   weekday_1  weekday_2  weekday_3  ...  mkt_unique_carrier_AA  \\\n",
       "0          0          0          0  ...                      1   \n",
       "1          0          0          0  ...                      0   \n",
       "2          0          0          0  ...                      0   \n",
       "3          1          0          0  ...                      0   \n",
       "4          0          1          0  ...                      0   \n",
       "\n",
       "   mkt_unique_carrier_AS  mkt_unique_carrier_B6 mkt_unique_carrier_DL  \\\n",
       "0                      0                      0                     0   \n",
       "1                      0                      0                     0   \n",
       "2                      0                      0                     0   \n",
       "3                      0                      0                     0   \n",
       "4                      0                      0                     0   \n",
       "\n",
       "  mkt_unique_carrier_F9 mkt_unique_carrier_G4 mkt_unique_carrier_HA  \\\n",
       "0                     0                     0                     0   \n",
       "1                     0                     0                     0   \n",
       "2                     0                     0                     0   \n",
       "3                     0                     0                     0   \n",
       "4                     0                     0                     0   \n",
       "\n",
       "   mkt_unique_carrier_NK  mkt_unique_carrier_UA  mkt_unique_carrier_WN  \n",
       "0                      0                      0                      0  \n",
       "1                      0                      1                      0  \n",
       "2                      0                      0                      1  \n",
       "3                      0                      0                      1  \n",
       "4                      0                      1                      0  \n",
       "\n",
       "[5 rows x 27 columns]"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_new.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c5f4cdc-291d-480f-acc3-4d03431c7268",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "bootcamp_env",
   "language": "python",
   "name": "bootcamp_env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
