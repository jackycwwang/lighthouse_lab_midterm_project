{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d544f8a1-ee71-40d9-bdc7-724dbb7d5ebb",
   "metadata": {},
   "source": [
    "## Data Wrangling and Data Exploration Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "3726db75-b88b-4423-a1b7-fc1a44ec1112",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import pandas as pd\n",
    "# import psycopg2\n",
    "# import pandas.io.sql as sqlio\n",
    "# import requests\n",
    "import help_functions as hf\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "69a792dd-00a5-444b-9d8f-55ad38c1369d",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Data_wrangling:\n",
    "    \n",
    "    def __init__(self, df):\n",
    "        self.df = df\n",
    "        \n",
    "    def drop_columns(self, column_names_as_list):\n",
    "        \"\"\" removes columns if exist in dataframe\n",
    "        Note ones that probably should be removed are [\"dup\", \"index\", \"no_name\", \"cancellation_code\" ]\"\"\"\n",
    "        for i in range(len(column_names_as_list)):\n",
    "            if column_names_as_list[i] in df:\n",
    "                self.df = self.df.drop(column_names_as_list[i], axis = 1)\n",
    "        return self.df\n",
    "\n",
    "\n",
    "def add_is_weekend_feature(df):\n",
    "    \"\"\" creates boolean column to indicate if week is weekend \n",
    "        https://pandas.pydata.org/docs/reference/api/pandas.DatetimeIndex.weekday.html\n",
    "        week starts 0 with monday - 0-5 are weekdays (0) and 6,7 weekends (1) \"\"\"\n",
    "\n",
    "    df['weekend'] = df['fl_date'].astype('datetime64[ns]')\n",
    "\n",
    "    f = lambda x: x.weekday()     \n",
    "    df['weekend'] = df['weekend'].apply(f).astype('int32')\n",
    "    df['weekend'].replace({\n",
    "            0:0,\n",
    "            1:0,\n",
    "            2:0,\n",
    "            3:0,\n",
    "            4:0,\n",
    "            5:0,\n",
    "            6:1,\n",
    "            7:1\n",
    "        }, inplace=True)\n",
    "    return df\n",
    "\n",
    "def make_categorical(df, cols):\n",
    "    '''\n",
    "    Convert columns in `cols` to type `categorical`\n",
    "    input: df - data frame, cols - a list of columns\n",
    "    output: a copy of the data frame with the converted columns\n",
    "    '''\n",
    "    col_dict = {col:'category' for col in cols}\n",
    "    df = df.astype(col_dict)\n",
    "    return df\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a3ed47d8-c3fb-4410-8df5-1b1d52a4a487",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "57ad28a3-a547-4995-9c13-2d7914bf48f7",
   "metadata": {},
   "source": [
    "## Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a984f61-75f5-45d0-9a82-360842c50574",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Preprocessing:\n",
    "    def __init__(self, df):\n",
    "        self.df = df\n",
    "        \n",
    "    def split_numeric_categorical(self):\n",
    "        pass\n",
    "        \n",
    "    def scale(self, scalar):\n",
    "        pass\n",
    "    \n",
    "    def remove_highly_correlated_columns(self):\n",
    "        pass\n",
    "    \n",
    "    def drop_targets(self):\n",
    "        \"\"\" removes target variables before modelling\"\"\"\n",
    "#         return drop_columns(self.df, ['carrier_delay', 'weather_delay', 'nas_delay', 'security_delay'])\n",
    "        pass\n",
    "   \n",
    "\n",
    "def remove_highly_correlated_features(df, correlation_threshold=0.8):\n",
    "    #     Anything above correlation threshold will be tossed\n",
    "    # Assumptions - all numeric, target variable removed\n",
    "    # step 1\n",
    "    df_corr = df.corr().abs()\n",
    "\n",
    "    # step 2\n",
    "    indices = np.where(df_corr > correlation_threshold)\n",
    "    indices = [(df_corr.index[x], df_corr.columns[y])\n",
    "    for x, y in zip(*indices)\n",
    "        if x != y and x < y]\n",
    "\n",
    "    # step 3\n",
    "    for idx in indices: #each pair\n",
    "        try:\n",
    "            df.drop(idx[1], axis = 1, inplace=True)\n",
    "        except KeyError:\n",
    "            pass\n",
    "    return(df)\n",
    "\n",
    " \n",
    "def remove_small_variance(x, variance_threshold = 0.1):\n",
    "    # Assumptions - target variable removed, df is numeric\n",
    "    # import:\n",
    "    # from sklearn.feature_selection import VarianceThreshold\n",
    "    vt = VarianceThreshold(variance_threshold)\n",
    "    x_transformed = vt.fit_transform(x)\n",
    "    selected_columns = x.columns[vt.get_support()]\n",
    "    x_transformed = pd.DataFrame(x_transformed, columns = selected_columns)\n",
    "    return(x_transformed)\n",
    "\n",
    "def remove_missing_values(x, missing_percent_drop_threshold=0.5):\n",
    "#     takes in dataframe, removes missing above a percent threshold - percent out of 1\n",
    "    total = x.isnull().sum().sort_values(ascending=False)\n",
    "    percent = (x.isnull().sum()/x.isnull().count()).sort_values(ascending=False)\n",
    "    missing_data = pd.concat([total, percent], axis=1, keys=['Total', 'Percent'])\n",
    "    missing_data.head(20)\n",
    "\n",
    "    to_drop = missing_data[missing_data['Percent'] > missing_percent_drop_threshold].index.tolist()\n",
    "    return(x.drop(to_drop, axis=1, inplace=True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "098a0707-3607-4725-a128-085fd621d0fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ONE HOT ENCODING\n",
    "\n",
    "\n",
    "\n",
    "# cat_feats = ['Item_Fat_Content', 'Item_Type', 'Outlet_Size', 'Outlet_Location_Type', 'Outlet_Type', 'Broad_Item_Type']\n",
    "# # cat_feats = data[].index.tolist()\n",
    "# df_dummy = pd.get_dummies(data[cat_feats])\n",
    "# df_dummy.head()\n",
    "\n",
    "# encode_and_bind(imdb_movies, 'Rated')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "id": "53369f89-496b-41e3-9d0c-5162cd8e3a0a",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'airport_count' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-137-37ab8fa83631>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     21\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mdf\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     22\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 23\u001b[0;31m \u001b[0mairport_count\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmake_bin_column\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mairport_count\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'total_flights'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m10\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'airport_count' is not defined"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "airport_count = make_bin_column(airport_count, 'total_flights', 10)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9e4257ee-df9e-4cd8-9955-d6baac40dbe2",
   "metadata": {},
   "source": [
    "# Formating Test Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b957ef91-140e-4324-84af-6b9d77955fac",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "5c6acfbd-4110-4d9a-b821-7239dc60d8da",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "df = pd.read_csv('../data/flights_samp.csv')\n",
    "\n",
    "# import fresh df from .csv before using this  otherwise will get double 00:00:00\n",
    "def convert_testtrain_data_to_test_format(df):\n",
    "    \"\"\" Convert our testing data to be in the same format as the data to test (drop columns and reformat date)\"\"\"\n",
    "    \n",
    "    #convert date to datetime with 0's\n",
    "    df.fl_date = (df.fl_date + ' 00:00:00')\n",
    "    pd.to_datetime(df['fl_date'])\n",
    "    \n",
    "    #drop columns not present in test format\n",
    "    df.drop(columns=['index', 'dep_time',\n",
    "       'dep_delay', 'taxi_out', 'wheels_off', 'wheels_on', 'taxi_in', 'arr_time', 'arr_delay', 'cancelled',\n",
    "       'cancellation_code', 'diverted', 'actual_elapsed_time', 'air_time', \n",
    "       'carrier_delay', 'weather_delay', 'nas_delay', 'security_delay',\n",
    "       'late_aircraft_delay', 'first_dep_time', 'total_add_gtime',\n",
    "       'longest_add_gtime', 'no_name'], inplace = True)\n",
    "    return df\n",
    "df_new = convert_testtrain_data_to_test_format(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "fc58ec62-f6b7-43d9-9e4c-82877ef15630",
   "metadata": {},
   "outputs": [],
   "source": [
    "# df_new\n",
    "def split_time_of_day_departure(df):\n",
    "    \"\"\" takes estimated time of departure and splits in to hours 24 hour clock (local time) \"\"\"\n",
    "    df['dep_hour'] = df['crs_dep_time']\n",
    "    df['dep_hour'] = np.floor(df['dep_hour']/100).astype(\"int\")\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "46051c94-d76e-4466-a2bb-b7bec4126f8f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# USE make_categorical(df, cols)!! will be easier for scaling\n",
    "\n",
    "def convert_from_test_format_to_fit_predict_format(df):\n",
    "    \"\"\"Adds in columns for model fitting and converts to numeric/ encoded categorical for ML model\"\"\"\n",
    "    \n",
    "    # Split crs_arr_time and crs_dep_time into hour of day (local)\n",
    "    df = hf.split_time_of_day_departure(df)\n",
    "    df = hf.split_time_of_day_arrival(df)\n",
    "    df.drop(columns=['crs_dep_time', 'crs_arr_time'], inplace=True)\n",
    "    \n",
    "    # Convert fl_date into day of week  # NOTE MAY WANT TO ADD BACK IN MONTH OR JAN 1 days\n",
    "    df = hf.add_weekday(df)  \n",
    "    df.drop(columns=['fl_date'], inplace=True)\n",
    "    df.weekday = df.weekday.astype(str)\n",
    "    df = hf.encode_and_bind(df, 'weekday')\n",
    "    \n",
    "    # Split city and state \n",
    "    hf.split_origin_city_state(df)\n",
    "    hf.split_dest_city_state(df)\n",
    "    df.drop(columns=['dest_city_name', 'origin_city_name'], inplace=True)\n",
    "    \n",
    "    # City - Encode (based on # flights)\n",
    "    city_dict = {'Chicago': 10,\n",
    "             'Atlanta': 9,\n",
    "             'New York': 8,\n",
    "             'Dallas/Fort Worth': 7,\n",
    "             'Denver': 6,\n",
    "             'Charlotte': 5,\n",
    "             'Houston': 4,\n",
    "             'Washington': 3,\n",
    "             'Los Angeles': 2,\n",
    "             'Seattle': 1}\n",
    "    df = df.replace({\"dest_city\":city_dict})\n",
    "    df = df.replace({\"origin_city\":city_dict})\n",
    "    \n",
    "    city_list = [10,9,8,7,6,5,4,3,2,1]\n",
    "    df.dest_city = np.where(df.dest_city.isin(city_list),df.dest_city, 0)\n",
    "    df.origin_city = np.where(df.origin_city.isin(city_list),df.origin_city, 0)\n",
    "    \n",
    "    # State - Encode (based on # flights)\n",
    "    state_dict = {'CA': 10,\n",
    "                 'TX': 9,\n",
    "                 'FL': 8,\n",
    "                 'IL': 7,\n",
    "                 'NY': 6,\n",
    "                 'GA': 5,\n",
    "                 'NC': 4,\n",
    "                 'CO': 3,\n",
    "                 'PA': 2,\n",
    "                 'WA': 1}\n",
    "\n",
    "    df = df.replace({\"dest_state\":state_dict})\n",
    "    df = df.replace({\"origin_state\":state_dict})\n",
    "    \n",
    "    state_list = [10,9,8,7,6,5,4,3,2,1]\n",
    "    df.dest_state = np.where(df.dest_state.isin(state_list),df.dest_state, 0)\n",
    "    df.origin_state = np.where(df.origin_state.isin(state_list),df.origin_state, 0)\n",
    "          \n",
    "    # Convert Carrier - Encode \n",
    "    df = hf.encode_and_bind(df, 'mkt_unique_carrier')\n",
    "\n",
    "    # Origin Airport - Encode top 10 (rest in 'other') OR BIN according to passenger or flight volume\n",
    "#     df.origin = \n",
    "    \n",
    "    # Dest Airport - Encode top 10 or bin according to passenger of flight volume \n",
    "#     df.dest =\n",
    "   \n",
    "    # Flight number ??? # drop for now? - See if routes that have more delays? Bin when find relationship with delays\n",
    "    df.drop(columns = ['mkt_carrier_fl_num'], inplace=True)\n",
    "    \n",
    "    # Drop rest\n",
    "    df.drop(columns=['branded_code_share', 'mkt_carrier','op_unique_carrier', 'tail_num', \n",
    "                     'op_carrier_fl_num', 'origin_airport_id', 'dest_airport_id', 'dup', 'flights'], inplace = True)\n",
    "    \n",
    "    # crs_elapsed # USE LONG HAUL SHORT HAUL\n",
    "    df['log_crs_elapsed_time'] = np.log(df.crs_elapsed_time)\n",
    "    df = hf.make_bin_column(df, 'log_crs_elapsed_time', 20) # 8-2/0.3\n",
    "    df.drop(columns = ['crs_elapsed_time'], inplace=True)\n",
    "    \n",
    "    return df\n",
    "\n",
    "    #/ distance choose one or other - correlated removal?\n",
    "\n",
    "df_new = convert_from_test_format_to_fit_predict_format(df_new)    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 190,
   "id": "c923f7bd-7440-4e96-b1a4-72de61188078",
   "metadata": {},
   "outputs": [],
   "source": [
    "hf.to_scale(df_new, ['crs_elapsed_time', 'distance'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "e67e0fab-4cb3-4438-b974-5aa128c4ecff",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mkt_unique_carrier</th>\n",
       "      <th>origin</th>\n",
       "      <th>dest</th>\n",
       "      <th>distance</th>\n",
       "      <th>dep_hour</th>\n",
       "      <th>arr_hour</th>\n",
       "      <th>weekday</th>\n",
       "      <th>weekday_0</th>\n",
       "      <th>weekday_1</th>\n",
       "      <th>weekday_2</th>\n",
       "      <th>...</th>\n",
       "      <th>mkt_unique_carrier_B6</th>\n",
       "      <th>mkt_unique_carrier_DL</th>\n",
       "      <th>mkt_unique_carrier_F9</th>\n",
       "      <th>mkt_unique_carrier_G4</th>\n",
       "      <th>mkt_unique_carrier_HA</th>\n",
       "      <th>mkt_unique_carrier_NK</th>\n",
       "      <th>mkt_unique_carrier_UA</th>\n",
       "      <th>mkt_unique_carrier_WN</th>\n",
       "      <th>log_crs_elapsed_time</th>\n",
       "      <th>log_crs_elapsed_time_bin</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>AA</td>\n",
       "      <td>LAX</td>\n",
       "      <td>ORD</td>\n",
       "      <td>1744.0</td>\n",
       "      <td>0</td>\n",
       "      <td>7</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>5.525453</td>\n",
       "      <td>17</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>UA</td>\n",
       "      <td>ORD</td>\n",
       "      <td>AZO</td>\n",
       "      <td>122.0</td>\n",
       "      <td>21</td>\n",
       "      <td>23</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>4.060443</td>\n",
       "      <td>13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>WN</td>\n",
       "      <td>OMA</td>\n",
       "      <td>PHX</td>\n",
       "      <td>1037.0</td>\n",
       "      <td>16</td>\n",
       "      <td>18</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>5.164786</td>\n",
       "      <td>16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>WN</td>\n",
       "      <td>TPA</td>\n",
       "      <td>MSY</td>\n",
       "      <td>488.0</td>\n",
       "      <td>10</td>\n",
       "      <td>10</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>4.553877</td>\n",
       "      <td>14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>UA</td>\n",
       "      <td>EWR</td>\n",
       "      <td>DCA</td>\n",
       "      <td>199.0</td>\n",
       "      <td>18</td>\n",
       "      <td>19</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>4.454347</td>\n",
       "      <td>14</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 30 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "  mkt_unique_carrier origin dest  distance  dep_hour  arr_hour weekday  \\\n",
       "0                 AA    LAX  ORD    1744.0         0         7       0   \n",
       "1                 UA    ORD  AZO     122.0        21        23       4   \n",
       "2                 WN    OMA  PHX    1037.0        16        18       5   \n",
       "3                 WN    TPA  MSY     488.0        10        10       1   \n",
       "4                 UA    EWR  DCA     199.0        18        19       2   \n",
       "\n",
       "   weekday_0  weekday_1  weekday_2  ...  mkt_unique_carrier_B6  \\\n",
       "0          1          0          0  ...                      0   \n",
       "1          0          0          0  ...                      0   \n",
       "2          0          0          0  ...                      0   \n",
       "3          0          1          0  ...                      0   \n",
       "4          0          0          1  ...                      0   \n",
       "\n",
       "   mkt_unique_carrier_DL  mkt_unique_carrier_F9  mkt_unique_carrier_G4  \\\n",
       "0                      0                      0                      0   \n",
       "1                      0                      0                      0   \n",
       "2                      0                      0                      0   \n",
       "3                      0                      0                      0   \n",
       "4                      0                      0                      0   \n",
       "\n",
       "  mkt_unique_carrier_HA mkt_unique_carrier_NK mkt_unique_carrier_UA  \\\n",
       "0                     0                     0                     0   \n",
       "1                     0                     0                     1   \n",
       "2                     0                     0                     0   \n",
       "3                     0                     0                     0   \n",
       "4                     0                     0                     1   \n",
       "\n",
       "  mkt_unique_carrier_WN  log_crs_elapsed_time  log_crs_elapsed_time_bin  \n",
       "0                     0              5.525453                        17  \n",
       "1                     0              4.060443                        13  \n",
       "2                     1              5.164786                        16  \n",
       "3                     1              4.553877                        14  \n",
       "4                     0              4.454347                        14  \n",
       "\n",
       "[5 rows x 30 columns]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_new.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c5f4cdc-291d-480f-acc3-4d03431c7268",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "bootcamp_env",
   "language": "python",
   "name": "bootcamp_env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
