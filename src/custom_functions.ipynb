{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d544f8a1-ee71-40d9-bdc7-724dbb7d5ebb",
   "metadata": {},
   "source": [
    "## Data Wrangling and Data Exploration Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "69a792dd-00a5-444b-9d8f-55ad38c1369d",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Data_wrangling:\n",
    "    \n",
    "    def __init__(self, df):\n",
    "        self.df = df\n",
    "        \n",
    "    def drop_columns(self, column_names_as_list):\n",
    "        \"\"\" removes columns if exist in dataframe\n",
    "        Note ones that probably should be removed are [\"dup\", \"index\", \"no_name\", \"cancellation_code\" ]\"\"\"\n",
    "        for i in range(len(column_names_as_list)):\n",
    "            if column_names_as_list[i] in df:\n",
    "                self.df = self.df.drop(column_names_as_list[i], axis = 1)\n",
    "        return self.df\n",
    "\n",
    "    def create_haul_type(self):\n",
    "        \"\"\" adds short:0, mid:1, long:2 range haul types from crs_elapsed_time (scheduled) \"\"\"\n",
    "\n",
    "        self.df[\"haul_type\"] = self.df['crs_elapsed_time']\n",
    "        self.df[\"haul_type\"].mask(self.df[\"haul_type\"].values < 180, 0, inplace=True)\n",
    "        self.df[\"haul_type\"].mask((self.df[\"haul_type\"] > 180) & (self.df[\"haul_type\"] < 360), 1, inplace=True)\n",
    "        self.df[\"haul_type\"].mask((self.df[\"haul_type\"] > 360), 2, inplace=True) \n",
    "        return self.df\n",
    "    \n",
    "\n",
    "\n",
    "    \n",
    "def split_time_of_day_departure(df):\n",
    "    \"\"\" takes estimated time of departure and splits in to hours 24 hour clock (local time) \"\"\"\n",
    "    df['dep_hour'] = df['crs_dep_time']\n",
    "    df['dep_hour'] = np.floor(df['dep_hour']/100).astype(\"int\")\n",
    "    return df['dep_hour']\n",
    "  \n",
    "    \n",
    "def split_time_of_day_arrival(df):\n",
    "    \"\"\" takes estimated time of arrival and splits in to hours 24 hour clock (local time) \"\"\"\n",
    "    df['arr_hour'] = df['crs_arr_time']\n",
    "    df['arr_hour'] = np.floor(df['arr_hour']/100).astype(\"int\")\n",
    "    return df['arr_hour']\n",
    "    \n",
    "    \n",
    "def split_dest_city_state(df):\n",
    "    \"\"\" separates destination city and states into own columns\"\"\"\n",
    "    df['dest_state'] = df['dest_city_name']\n",
    "    df['dest_city'] = df['dest_city_name']\n",
    "    \n",
    "    f_state= lambda x: x.split(sep=', ')[1]\n",
    "    f_city= lambda x: x.split(sep=', ')[0]\n",
    "\n",
    "    df['dest_state'] = df['dest_state'].apply(f_state)\n",
    "    df['dest_city'] = df['dest_city'].apply(f_city)\n",
    "    return df\n",
    "\n",
    "\n",
    "def split_origin_city_state(df):\n",
    "    \"\"\" separates origin city and states into own columns\"\"\"\n",
    "    df['origin_state'] = df['origin_city_name']\n",
    "    df['origin_city'] = df['origin_city_name']\n",
    "    \n",
    "    f_state= lambda x: x.split(sep=', ')[1]\n",
    "    f_city= lambda x: x.split(sep=', ')[0]\n",
    "\n",
    "    df['origin_state'] = df['origin_state'].apply(f_state)\n",
    "    df['origin_city'] = df['origin_city'].apply(f_city)\n",
    "    return df\n",
    "\n",
    "\n",
    "def add_is_weekend_feature(df):\n",
    "    \"\"\" creates boolean column to indicate if week is weekend \n",
    "        https://pandas.pydata.org/docs/reference/api/pandas.DatetimeIndex.weekday.html\n",
    "        week starts 0 with monday - 0-5 are weekdays (0) and 6,7 weekends (1) \"\"\"\n",
    "\n",
    "    df['weekend'] = df['fl_date'].astype('datetime64[ns]')\n",
    "\n",
    "    f = lambda x: x.weekday()     \n",
    "    df['weekend'] = df['weekend'].apply(f).astype('int32')\n",
    "    df['weekend'].replace({\n",
    "            0:0,\n",
    "            1:0,\n",
    "            2:0,\n",
    "            3:0,\n",
    "            4:0,\n",
    "            5:0,\n",
    "            6:1,\n",
    "            7:1\n",
    "        }, inplace=True)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "57ad28a3-a547-4995-9c13-2d7914bf48f7",
   "metadata": {},
   "source": [
    "## Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a984f61-75f5-45d0-9a82-360842c50574",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Preprocessing:\n",
    "    def __init__(self, df):\n",
    "        self.df = df\n",
    "        \n",
    "    def split_numeric_categorical(self):\n",
    "        pass\n",
    "        \n",
    "    def scale(self, scalar):\n",
    "        pass\n",
    "    \n",
    "    def remove_highly_correlated_columns(self):\n",
    "        pass\n",
    "    \n",
    "    def drop_targets(self):\n",
    "        \"\"\" removes target variables before modelling\"\"\"\n",
    "#         return drop_columns(self.df, ['carrier_delay', 'weather_delay', 'nas_delay', 'security_delay'])\n",
    "        pass\n",
    "   \n",
    "\n",
    "def remove_highly_correlated_features(df, correlation_threshold=0.8):\n",
    "    #     Anything above correlation threshold will be tossed\n",
    "    # Assumptions - all numeric, target variable removed\n",
    "    # step 1\n",
    "    df_corr = df.corr().abs()\n",
    "\n",
    "    # step 2\n",
    "    indices = np.where(df_corr > correlation_threshold) \n",
    "    indices = [(df_corr.index[x], df_corr.columns[y]) \n",
    "    for x, y in zip(*indices)\n",
    "        if x != y and x < y]\n",
    "\n",
    "    # step 3\n",
    "    for idx in indices: #each pair\n",
    "        try:\n",
    "            df.drop(idx[1], axis = 1, inplace=True)\n",
    "        except KeyError:\n",
    "            pass\n",
    "    return(df)\n",
    "\n",
    " \n",
    "def remove_small_variance(x, variance_threshold = 0.1):\n",
    "    # Assumptions - target variable removed, df is numeric\n",
    "    # import:\n",
    "    # from sklearn.feature_selection import VarianceThreshold\n",
    "    vt = VarianceThreshold(variance_threshold)\n",
    "    x_transformed = vt.fit_transform(x)\n",
    "    selected_columns = x.columns[vt.get_support()]\n",
    "    x_transformed = pd.DataFrame(x_transformed, columns = selected_columns)\n",
    "    return(x_transformed)\n",
    "\n",
    "def remove_missing_values(x, missing_percent_drop_threshold=0.5):\n",
    "#     takes in dataframe, removes missing above a percent threshold - percent out of 1\n",
    "    total = x.isnull().sum().sort_values(ascending=False)\n",
    "    percent = (x.isnull().sum()/x.isnull().count()).sort_values(ascending=False)\n",
    "    missing_data = pd.concat([total, percent], axis=1, keys=['Total', 'Percent'])\n",
    "    missing_data.head(20)\n",
    "\n",
    "    to_drop = missing_data[missing_data['Percent'] > missing_percent_drop_threshold].index.tolist()\n",
    "    return(x.drop(to_drop, axis=1, inplace=True))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "bootcamp_env",
   "language": "python",
   "name": "bootcamp_env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
